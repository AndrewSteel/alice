services:
  ollama-3090:
    image: ollama/ollama:latest
    container_name: ollama-3090
    restart: unless-stopped
    networks: [frontend, app_int]
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=-1
      - HF_HOME=/data/hf
      - XDG_CACHE_HOME=/data/cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["GPU-c15bd736-8523-5516-2468-3fb450250bab"]  # RTX 3090
              capabilities: ["gpu"]
    volumes:
      - /srv/hot/models/ollama:/root/.ollama/models
    healthcheck:
      test: ["CMD-SHELL", "ollama ps >/dev/null 2>&1 || exit 1"]
      interval: 60s
      timeout: 5s
      start_period: 30s
      retries: 10

  ollama-titan:
    image: ollama/ollama:latest
    container_name: ollama-titan
    restart: unless-stopped
    networks: [app_int, frontend]
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=-1
      - HF_HOME=/data/hf
      - XDG_CACHE_HOME=/data/cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["GPU-ed6554a1-fe67-5286-11c3-a19c2f3554a6"]  # TITAN X
              capabilities: ["gpu"]
    volumes:
      - /srv/hot/models/ollama:/root/.ollama/models
    healthcheck:
      test: ["CMD-SHELL", "ollama ps >/dev/null 2>&1 || exit 1"]
      interval: 120s
      timeout: 5s
      start_period: 30s
      retries: 10

networks:
  app_int:
  frontend:
    external: true
    name: frontend
